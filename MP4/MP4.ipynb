{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MP 4: Calibration and RANSAC\n",
    "\n",
    "**Due date**: April 4, 2021 at 9:45am.\n",
    "\n",
    "**Instructions**: Read and complete the problems below. In this assignment, you should be switched over to a local install. \n",
    "\n",
    "To submit your assignment, perform the following:\n",
    "\n",
    "1. Double-check that your programs run without error.\n",
    "2. Send this file, all of your .py files and any other files you used in your programs on Moodle [http:/learn.illinois.edu](http:/learn.illinois.edu).  Do not rename the files.\n",
    "3. If you are using any external libraries other than the ones that are indicated during the installation process, include a README file indicating which library and version you are using.  To be on the safe side, you should include a backup procedure until the graders verify that they are able to support use of that library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Estimation and sensitivity\n",
    "\n",
    "In this problem, a simple dataset with 3D input *x* and 2D output *y* is given to you.  You will investigate the behavior of two model classes, an affine model and a quadratic model.\n",
    "\n",
    "* The affine model states that $y = Ax+b $ where $\\theta=stack(b,A)$ are the 8 model parameters stacked into a single vector (e.g., $\\theta = (b_1, b_2, a_{11}, a_{12}, a_{13}, a_{21}, a_{22}, a_{23})$).\n",
    "* The quadratic model states that $$y_i = \\theta_{i0} + \\theta_{i1}x_1 + \\theta_{i2}x_2 + \\theta_{i3}x_3 +  \\theta_{i11}x_1^2 + \\theta_{i12}x_1 x_2 + \\theta_{i13}x_1 x_3 + \\theta_{i22}x_2^2 + \\theta_{i23}x_2 x_3 + \\theta_{i33} x_3^2$$ for $i=1,2$. The first 4 parameters in this set of coefficients also exist in the affine model, but the remaining 6 multiply the order-2 monomials $x_1^2$, $x_1 x_2$, $x_1 x_3$, $x_2^2$, $x_2 x_3$, and $x_3^2$. The 20-parameter vector is then $\\theta=(\\theta_{10},\\theta_{20},\\theta_{11},...,\\theta_{13},\\theta_{21},...,\\theta_{23},\\theta_{111},...,\\theta_{133},\\theta_{211},...,\\theta_{233})$.\n",
    "\n",
    "### Problem 1.A\n",
    "\n",
    "For a given model, the loss function measures the error between a prediction $f(x;\\theta)$ and the output $y$ for a single datapoint $(x,y)$.  Implement the models and the squared L2 loss function $\\|y-f(x;\\theta)\\|$ for each model in the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.optimize\n",
    "\n",
    "############################# Problem 1.A code goes here ############################\n",
    "\n",
    "def affine_model(x,theta):\n",
    "    #implement the first model here\n",
    "    return [x[0],x[1]]\n",
    "\n",
    "def quadratic_model(x,theta):\n",
    "    #implement the second model here\n",
    "    return [x[0],x[1]]\n",
    "\n",
    "def affine_squared_L2_loss(y,x,theta):\n",
    "    #implement the loss function here\n",
    "    return 0\n",
    "\n",
    "def quadratic_squared_L2_loss(y,x,theta):\n",
    "    #implement the loss function here\n",
    "    return 0\n",
    "\n",
    "#####################################################################################,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Written.**  In the quadratic model, why did we omit parameters $\\theta_{i21}$, $\\theta_{i31}$, and $\\theta_{i32}$ which would act as coefficients of the monomials $x_2 x_1$, $x_3 x_1$, and $x_3 x_2$, respectively?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.B\n",
    "\n",
    "To estimate the parameters, you will construct objective functions `affine_objective` and `quadratic_objective` that sum the loss over the provided dataset.  To minimize the objective function, use the [scipy.optimize.minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) function.  I suggest using the 'BFGS' method and no more than 30 or 50 iterations.  Note that you will either need to write your objective function as a 1-parameter wrapper function over the optimization parameters `theta`, or to use the `args` argument to `minimize` to pass in the dataset.  Your code that calls `minimize` should input an initial guess `x0=theta0` and extract the results from the returned `OptimizeResult`.\n",
    "\n",
    "Note: on the ground truth optimization, your optimizer for the quadratic model should return an objective value (`OptimizeResult.fun`) close to zero.\n",
    "\n",
    "**Written.** Report the estimated values for each model and their errors.  Compare the magnitudes of the affine model and their corresponding terms in the quadratic model.  Offer an explanation of what you observe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Problem 1.B code goes here ############################\n",
    "\n",
    "def affine_objective(theta,dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        theta: the parameter vector\n",
    "        dataset: a list of pairs (x,y)\n",
    "    \"\"\"\n",
    "    #implement the objective function\n",
    "    return 0\n",
    "\n",
    "def quadratic_objective(theta,dataset):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        theta: the parameter vector\n",
    "        dataset: a list of pairs (x,y)\n",
    "    \"\"\"\n",
    "    #implement the objective function\n",
    "    return 0\n",
    "\n",
    "def optimize_affine(dataset):\n",
    "    initial_guess = np.array([0]*8)\n",
    "    return initial_guess\n",
    "\n",
    "def optimize_quadratic(dataset):\n",
    "    initial_guess = np.array([0]*20)\n",
    "    return initial_guess\n",
    "\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Driver code\n",
    "\n",
    "dataset_x = np.load('fitting/dataset_x.npy')\n",
    "dataset_y = np.load('fitting/dataset_y.npy')\n",
    "dataset = list(zip(dataset_x,dataset_y))\n",
    "\n",
    "affine_parameters = optimize_affine(dataset)\n",
    "quadratic_parameters = optimize_quadratic(dataset)\n",
    "print(\"Affine:\",' '.join([\"%.3f\"%v for v in affine_parameters]))\n",
    "print(\"Quadratic:\",' '.join([\"%.3f\"%v for v in quadratic_parameters]))\n",
    "\n",
    "dataset_y_ground_truth = np.load('fitting/dataset_y_ground_truth.npy')\n",
    "dataset_ground_truth = list(zip(dataset_x,dataset_y_ground_truth))\n",
    "\n",
    "affine_parameters_ground_truth = optimize_affine(dataset_ground_truth)\n",
    "quadratic_parameters_ground_truth = optimize_quadratic(dataset_ground_truth)\n",
    "\n",
    "print(\"Affine ground truth:\",' '.join([\"%.3f\"%v for v in affine_parameters_ground_truth]))\n",
    "print(\"Quadratic ground truth:\",' '.join([\"%.3f\"%v for v in quadratic_parameters_ground_truth]))\n",
    "\n",
    "print(\"Affine errors:\",' '.join([\"%.3f\"%abs(v) for v in affine_parameters-affine_parameters_ground_truth]))\n",
    "print(\"Quadratic errors:\",' '.join([\"%.3f\"%abs(v) for v in quadratic_parameters-quadratic_parameters_ground_truth]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 1.C. Errors and sensitivity\n",
    "\n",
    "To estimate how sensitive the parameter estimates are to noise, we will use the inverse of the hessian of the objective function.  Use the approximation $var(\\theta) \\approx O(diag(H^{-1})/n)$ with $H$ the hessian of the sum-of-squared errors objective at $\\theta$ and $n$ the number of samples in the dataset.  You should return the *standard error* of the parameter estimate, which is the vector of square roots of the variances.  (Remark: this approximation is based on the Cramer-Rao lower bound in statistics.)\n",
    "\n",
    "To approximate the Hessian, you should use the *finite difference* approximation $$H_{ij} \\approx (f(\\theta + e_i h + e_j h) - f(\\theta + e_i h) - f(\\theta + e_j h) + f(\\theta))/h^2$$ where $e_i$ is the elementary basis vector (i.e., the vector of all 0's except a 1 in the i'th entry) and *h* is a step size parameter.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################# Problem 1.C code goes here ############################\n",
    "\n",
    "def affine_sensitivity(theta,dataset):\n",
    "    return [0]*len(theta)\n",
    "\n",
    "def quadratic_sensitivity(theta,dataset):\n",
    "    return [0]*len(theta)\n",
    "\n",
    "#####################################################################################"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below will run your sensitivity estimation code for the normal 100-example dataset as well as a 20-example subset.  \n",
    "\n",
    "**Written.** Why are parameters estimated to be more sensitive for the quadratic model? Why are parameters estimated to be more sensitive when the dataset is small?  Do the estimates correspond in magnitude to the empirical errors?\n",
    "\n",
    "What happens to the estimated sensitivies when the dataset size drops below 10?  Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Affine sensitivity:\\t\",' '.join([\"%.3f\"%v for v in affine_sensitivity(affine_parameters,dataset)]))\n",
    "print(\"Affine errors:\\t\\t\",' '.join([\"%.3f\"%abs(v) for v in affine_parameters-affine_parameters_ground_truth]))\n",
    "print(\"Quadratic sensitivity:\\t\",' '.join([\"%.3f\"%v for v in quadratic_sensitivity(quadratic_parameters,dataset)]))\n",
    "print(\"Quadratic errors:\\t\",' '.join([\"%.3f\"%abs(v) for v in quadratic_parameters-quadratic_parameters_ground_truth]))\n",
    "\n",
    "dataset_small = dataset[:20]\n",
    "affine_parameters_small = optimize_affine(dataset_small)\n",
    "quadratic_parameters_small = optimize_quadratic(dataset_small)\n",
    "print()\n",
    "print(\"Affine sensitivity, small dataset:\\t\",' '.join([\"%.3f\"%v for v in affine_sensitivity(affine_parameters_small,dataset_small)]))\n",
    "print(\"Affine errors, small dataset:\\t\\t\",' '.join([\"%.3f\"%abs(v) for v in affine_parameters_small-affine_parameters_ground_truth]))\n",
    "print(\"Quadratic sensitivity, small dataset:\\t\",' '.join([\"%.3f\"%v for v in quadratic_sensitivity(quadratic_parameters_small,dataset_small)]))\n",
    "print(\"Quadratic errors, small dataset:\\t\",' '.join([\"%.3f\"%abs(v) for v in quadratic_parameters_small-quadratic_parameters_ground_truth]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Plane extraction\n",
    "\n",
    "We're going to perform intrinsics calibration of the SR300 depth camera by pointing it at perpendicular planes.  The first step is to extract the points that make up these planes.  To do so, in this problem we will implement a RANSAC-based plane extractor.  To keep your algorithms running at a reasonable speed, it will be helpful for you to learn array addressing in Numpy; running for loops in Python code is much, much slower.\n",
    "\n",
    "The calibration color and depth images are stored in the `calibration/` folder, and they will be automatically loaded for you.  Specifically, we will be using the `depth_aligned_X.png` files.\n",
    "\n",
    "### Problem 2.A\n",
    "\n",
    "Implement a RANSAC algorithm under `extract_planes_ransac_a` in `planes.py`.  For `N` iterations, sample subsets of `m` points, fit planes, and examine how many inliers there are.  An inlier to a plane `(a,b,c,d)` is defined by $|(a,b,c)^T \\mathbf{p} + d| < $ `inlier_tolerance`.\n",
    "\n",
    "In this part, you will produce a naive implementation that outputs any inlier sets that are at least as large as `inlier_count`.   You will represent an inlier set using just a list of integers; the result from this function is a list of lists of integers.  The `fit_plane3` and `fit_plane` subroutines will allow you to fit these planes easily.\n",
    "\n",
    "Running `planes.py` will perform this fitting for each of the depth images; the result will look something like this:\n",
    "\n",
    "![Example output](example_output/planes_2a.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.B\n",
    "\n",
    "The naive extractor obviously has problems, the main one being that the inlier sets overlap significantly.  Implement a refined version in `extract_planes_ransac_b` that \n",
    "\n",
    "1. Does not sample from candidate points that already belong to an extracted plane,\n",
    "2. After the main RANSAC iteration, assigns points to the largest plane (in terms of # of inliers) for which they are an inlier, and \n",
    "3. Discards planes that have fewer than `inlier_count` points assigned to them, after step 2.\n",
    "\n",
    "After uncommenting `PROBLEM='2b'`, the result should be much better, looking something like this:\n",
    "\n",
    "![Example output](example_output/planes_2b.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 2.C\n",
    "\n",
    "There are still some small errors near the boundary of the plane segmentation, which become more obvious when the inlier threshold is set larger.  In `extract_planes_ransac_c`, if a point can be an inlier for multiple planes, assign it to the one for which it is the best fit (i.e., the point-to-plane distance is lowest).  You might also modify the code to provide normals to your code, which you can use for even better assignments. \n",
    "\n",
    "After uncommenting `PROBLEM='2c'`, examine the boundaries between planes to ensure that you're getting reasonable results.   Tune the parameters to yield results that are as good as possible -- you might also want the parameters to depend on the scale of the input.  (Scan 9 is particularly challenging).\n",
    "\n",
    "![Example output](example_output/planes_2c.png)\n",
    "\n",
    "Then, for problem 3, click through each of the scans (or comment out the `vis.dialog()` call) to output the sets of planes for each image (the `planesets` variable).  This will output a file called `planesets.json` which you will include in your submission."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Intrinsic calibration\n",
    "\n",
    "Now, we will assume that we are given a default calibration for the camera taken from the manufacturer's specs, and use optimization to calibrate the $f_x, f_y, c_x, $ and $c_y$ intrinsic parameters.\n",
    "\n",
    "### Problem 3.A\n",
    "\n",
    "In `depth_calibration.py`, implement the `mutual_orthogonality()` function to determine how close to orthogonal are the planes determined for each scan.  You will keep the point indices belonging to each plane (the `planesets` variable) the same regardless of the setting of `fx,fy,cx,cy`, but you will change the points themselves.  In particular, see lines 165-169 of `rgbd.py` to see how the points are affected by these parameters. \n",
    "\n",
    "To measure orthogonality may choose to use an absolute value of the dot product (i.e., $|\\cos \\theta|$), dot product squared, angular error ($|90^\\circ - \\theta|$), or angular error squared.  To aggregate, you can either sum or average.  In any case, the result should be minimized when the normals of all planes detected for a scan are perfectly at 90 degrees.  (Note that for scan 11, two of the planes are parallel -- you should not penalize them.)\n",
    "\n",
    "In the space below for written answers, describe the orthogonality metric you used and the method you used for aggregation.  Also, examine which of the scans produces the worst result(s), and check the visualization in `planes.py`.  Explain why those particular scans seemed problematic.\n",
    "\n",
    "### Problem 3.B\n",
    "\n",
    "Now, implement the `calibrate_intrinics_fxfy` function to optimize your metric only over the `fx,fy` variables, keeping `cx,cy` fixed.  Use the [scipy.optimize.minimize](https://docs.scipy.org/doc/scipy/reference/generated/scipy.optimize.minimize.html) function to minimize an objective function.  I suggest using the 'Nelder-Mead' method, which is a derivative-free method, and no more than 30 or 50 iterations.  Note that you will need to write your objective function as a 1-parameter wrapper function such that it accepts the optimization parameters as an array `x`.  Your code that calls `minimize` should input an initial guess `x0=(fx,fy)` and extract the results from the returned array.\n",
    "\n",
    "In the space below for written answers, report the initial and final parameter values, and the initial and final objective function values.  Did this seem to converge to reasonable values?  Compare with the parameters set in `calibration/color_intrinsics.json` (note: we're not using `depth_intrinsics.json` because the depth images have been aligned to the color camera).\n",
    "\n",
    "### Problem 3.C\n",
    "\n",
    "Now, implement the `calibrate_intrinics_all` function to optimize your metric over all four variables.   In the space below for written answers, report the initial and final parameter values, and the initial and final objective function values.  Did this seem to converge to reasonable values compared to `calibration/color_intrinsics.json`?  (Note that the Intel Realsense library refers to `cx, cy` as `ppx, ppy`.)  Explain why or why not.\n",
    "\n",
    "Is this problem identifiable?  Give a rough justification for your answer (i.e., by verbally describing the geometry of the situation).\n",
    "\n",
    "### Problem 3.D (IR2 section only)\n",
    "\n",
    "Provide a rigorous mathematical justification for whether the full optimization in this problem is identifiable or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written responses\n",
    "\n",
    "### Written response for Problem 1.A\n",
    "\n",
    "Put your answer here.\n",
    "\n",
    "### Written response for Problem 1.B\n",
    "\n",
    "Put your answer here.\n",
    "\n",
    "### Written response for Problem 1.C\n",
    "\n",
    "Put your answer here.\n",
    "\n",
    "### Written response for Problem 3.A\n",
    "\n",
    "Put your answer here.\n",
    "\n",
    "### Written response for Problem 3.B\n",
    "\n",
    "Put your answer here.\n",
    "\n",
    "### Written response for Problem 3.C\n",
    "\n",
    "Put your answer here.\n",
    "\n",
    "\n",
    "### Written response for Problem 3.D (IR2 section only)\n",
    "\n",
    "Put your answer here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
