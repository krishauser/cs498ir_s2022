{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MP 6: Self-supervised Pick and Place\n",
    "\n",
    "**Due date**: May 4, 2022 at 9:45am.\n",
    "\n",
    "**Instructions**: Read and complete the problems below. In this assignment, you should be switched over to a local install. \n",
    "\n",
    "To submit your assignment, perform the following:\n",
    "\n",
    "1. Double-check that your programs run without error.\n",
    "2. Submit this file, all of your .py files, 10 examples (from Problem 1), and any models used in your final pick-and-place planner on Moodle [http:/learn.illinois.edu](http:/learn.illinois.edu). \n",
    "3. If you are using any external libraries other than the ones that are indicated during the installation process, include a README file indicating which library and version you are using.  To be on the safe side, you should include a backup procedure until the graders verify that they are able to support use of that library."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context\n",
    "\n",
    "This assignment brings together bits and pieces from all that we've learned over the semester, using  the Wlkata Mirobot with a vacuum gripper and an overhead RGBD camera.  The goal is to be able to clear all the blocks to a pile off to the side. If you run `python simulated_robot.py` you will be able to control the robot manually by right-dragging with the mouse, and pressing 'v' to toggle the simulated vacuum gripper.\n",
    "\n",
    "The main class you will use to interact with the robot is `SimulatedMirobotWithVacuumAndSensor`, found in `simulated_robot.py`. If you are successful, we will be able to replace this with the real robot using the same API, and we can test your code on the real robot!\n",
    "\n",
    "The underlying arm controller respects the [Klampt Control package](http://motion.cs.illinois.edu/software/klampt/latest/pyklampt_docs/Manual-Control.html) API.  Your code will be operated in synchronous mode, which steps your application code in alignment with the underlying controller."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 1: Pick-and-Place using Omniscient Sensing\n",
    "\n",
    "In `pick_and_place_omniscient.py` you are given all of the object poses in the scene. \n",
    "\n",
    "1.A. Use this information to implement a behavior that picks all of the objects using the vacuum and places them in the target location indicated at the top of the file.\n",
    "\n",
    "You will want to implement a state machine that waits until each movement is done. Because we know that there are no obstacles, you don't strictly need to perform motion planning.\n",
    "\n",
    "1.B. In the written responses below, describe what measures you needed to take in your implementation to counteract the positioning errors of this inaccurate robot."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 2: Self-Supervised Simulation-based Training\n",
    "\n",
    "In `self_supervised.py`, you will implement a self-supervised method for generating data to predict whether an object is graspable. \n",
    "\n",
    "2.A. Implement a behavior that moves the robot out of the way, reads the RGB-D image, attempts a grasp at a certain location (according to your heuristic), tests whether the grasp was successful, and then drops the object.  Afterwards, you will save the images and the grasp data to disk in the `generated_data` folder.\n",
    "\n",
    "It is up to you whether you wish to regress a grasp location or a grasp score.\n",
    "\n",
    "2.B. Implement a world reset function that allows you to re-attempt grasps after each attempt.  Use this to generate many examples automatically.\n",
    "\n",
    "2.C. In the written responses below, describe in the area for written responses the heuristic that you use for generated grasps.  How did you attain more positive grasps than random sampling?\n",
    "\n",
    "2.D. Save 10 example image pairs in PNG format and 10 example grasp data in whatever format you prefer.  Include these with your submission.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem 3: Pick-and-Place using Images\n",
    "\n",
    "Finally, in `pick_and_place.py` you are only given images of the scene. You should NOT inspect the world model or simulation to determine where the objects are.\n",
    "\n",
    "3.A. Use the provided information to implement the same pick and place behavior, only using image information, flow sensor information, and the calibrated camera transform `Tcamera_world`.\n",
    "\n",
    "3.B. In the written responses below, describe the process that you used to predict where to grasp objects.  Be specific about what model you used for learning, and how you convert the learned quantities to 3D coordinates.\n",
    "\n",
    "3.C. In the written responses below, describe sources of error that influence this pick-and-place method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Written responses\n",
    "\n",
    "### Written response for Problem 1.B\n",
    "\n",
    "Put your answer here.\n",
    "\n",
    "### Written response for Problem 2.B\n",
    "\n",
    "Put your answer here.\n",
    "\n",
    "\n",
    "### Written response for Problem 3.B\n",
    "\n",
    "Put your answer here. \n",
    "\n",
    "### Written response for Problem 3.C\n",
    "\n",
    "Put your answer here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": false,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
